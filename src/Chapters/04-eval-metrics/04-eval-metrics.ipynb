{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f82b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759f5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"Data/CreditScoring.csv\")\n",
    "full_data_path = Path.cwd().parents[1].joinpath(data_path)\n",
    "df = pd.read_csv(full_data_path)\n",
    "\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e71752",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60c1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the numerical variables:\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95d05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clients with unknown default status\n",
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d580d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable\n",
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e09708d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority     int64\n",
       "home         object\n",
       "time          int64\n",
       "age           int64\n",
       "marital      object\n",
       "records      object\n",
       "job          object\n",
       "expenses      int64\n",
       "income        int64\n",
       "assets        int64\n",
       "debt          int64\n",
       "amount        int64\n",
       "price         int64\n",
       "default       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019592c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45403752",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c23819",
   "metadata": {},
   "source": [
    "### Execute the preparation code from the starter notebook\n",
    "Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a756c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4db028a",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "- For each numerical variable, use it as score and compute AUC with the \"default\" variable \n",
    "- Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "(e.g. -df_train['expenses'])\n",
    "\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- seniority\n",
    "- time\n",
    "- income\n",
    "- debt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d2be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e9cdff",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc523b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "049c3d55",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.512\n",
    "- 0.612\n",
    "- 0.712\n",
    "- 0.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be66bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85090cb4",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "- Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "- For each threshold, compute precision and recall\n",
    "- Plot them\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "- 0.2\n",
    "- 0.4\n",
    "- 0.6\n",
    "- 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4e879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e6d733",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "F1 = 2 * P * R / (P + R)\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- 0.3\n",
    "- 0.5\n",
    "- 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f66af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eb8681f",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "- Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- 0.001\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bfdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ba1ab19",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "- Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "- Initialize KFold with the same parameters as previously\n",
    "- Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "- Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ab2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
